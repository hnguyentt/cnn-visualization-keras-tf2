{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/nguyenhoa93/cnn-visualization-keras-tf2/blob/master/visualization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for Colab\n",
    "import sys\n",
    "from pathlib import Path\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "srcpath = Path(\"src\")\n",
    "\n",
    "if IN_COLAB and not srcpath.exists(): # if running in Colab --> download src if not exists\n",
    "    !apt-get install subversion\n",
    "    !svn checkout https://github.com/nguyenhoa93/cnn-visualization-keras-tf2/trunk/src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "474295917d714903bd93fbf7afe7e2f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridspecLayout(children=(FileUpload(value={}, description='Upload', layout=Layout(grid_area='widget001')), Butâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import io\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.imagenet_utils import decode_predictions\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Javascript, HTML, clear_output, IFrame\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, AppLayout, GridspecLayout\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.utils import model_dicts, array2bytes, create_model, get_conv_layers\n",
    "from src.guidedBacprop import GuidedBackprop, deprocess_image\n",
    "from src.gradcam import GradCAM, overlay_gradCAM\n",
    "from src.filtersVis import extract_filter, vis_filter\n",
    "from src.featuresVis import FeaturesExtraction, vis_feature_map\n",
    "from src.deepdream import preprocess_deep_dream, deprocess_deep_dream, DeepDream\n",
    "\n",
    "def create_expanded_button(description, button_style):\n",
    "    return widgets.Button(description=description, button_style=button_style,\n",
    "                          layout=widgets.Layout(height='auto', width='auto'))\n",
    "\n",
    "model_ls = [\"--Select\"] + list(model_dicts.keys())\n",
    "layer_ls = [\"--Select\"]\n",
    "method_ls = [\"--Select\",\"Filter vis\", \"Feature map vis\",\"Guided Backprop\"]\n",
    "class_ls = [\"--Select\"]\n",
    "\n",
    "uploader = widgets.FileUpload()\n",
    "show_but = create_expanded_button(\"Show image\",\"success\")\n",
    "header = widgets.HTML('<font color=\"#1f77b4\" face=\"sans-serif\"><center><h1>Visualize and Explain Networks</h1><h3>All pre-trained models (Keras) on ImageNet</h3><hr style=\"height:2px;border-width:0;color:gray;background-color:gray\"></center></font>',\n",
    "                      layout=widgets.Layout(height='auto'))\n",
    "models = widgets.Dropdown(options=model_ls, description=\"Model: \", layout={\"width\":\"auto\"},disabled=False)\n",
    "layers = widgets.Dropdown(options=layer_ls, description=\"Layer: \", layout={\"width\":\"auto\"},disabled=False)\n",
    "vis_but = create_expanded_button(\"Visualize\",\"info\")\n",
    "methods = widgets.Dropdown(options=method_ls, description=\"Vis method: \", layout={\"width\":\"auto\"},disabled=False)\n",
    "explain_but = create_expanded_button(\"Predict & Explain\",\"warning\")\n",
    "classes = widgets.Dropdown(options=class_ls, description=\"Vis class: \", layout={\"width\":\"auto\"},disabled=False)\n",
    "visclass_but = create_expanded_button(\"Vis this class\",\"danger\")\n",
    "deep_dream_but = create_expanded_button(\"Generate\",\"primary\")\n",
    "deco = widgets.Image(\n",
    "    value=open(\"images/lapan.jpg\",\"rb\").read(),\n",
    "    format=\"jpg\",\n",
    "    width=\"auto\",\n",
    "    height=\"auto\",\n",
    "    align=\"center-align\"\n",
    ")\n",
    "\n",
    "# Layout\n",
    "grid = GridspecLayout(15,30,height=\"600px\")\n",
    "grid[0,:4] = uploader\n",
    "grid[0,5:9] = show_but\n",
    "grid[0:3,10:] = header\n",
    "grid[2,:9] = models\n",
    "grid[3,:9] = widgets.HTML('<hr style=\"height:2px;border-width:0;color:gray;background-color:gray\"><font color=\"gray\" face=\"sans-serif\"><center><h4>Filter and Feature Map Vis</h4></center>')\n",
    "grid[4,:9] = layers\n",
    "grid[5,:9] = methods\n",
    "grid[7,:9] = vis_but\n",
    "grid[8,:9] = widgets.HTML('<hr style=\"height:2px;border-width:0;color:gray;background-color:gray\"><font color=\"gray\" face=\"sans-serif\"><center><h4>Explanation</h4></center>')\n",
    "grid[9,:9] = explain_but\n",
    "grid[11,:9] = classes\n",
    "grid[13,:9] = widgets.HTML('<hr style=\"height:2px;border-width:0;color:gray;background-color:gray\"><font color=\"gray\" face=\"sans-serif\"><center><h4>Deep Dream</h4></center>')\n",
    "grid[14,:9] = deep_dream_but\n",
    "grid[4:12,10:] = deco\n",
    "grid[14,10:] = widgets.HTML('<font color=\"gray\" face=\"sans-serif\"><center><h4>Lang Co, Hue, Vietnam</h4></center>')\n",
    "display(grid)\n",
    "\n",
    "def on_change_model(change):\n",
    "    if change[\"type\"] == \"change\" and change[\"name\"] == \"value\":\n",
    "        chosen_model = change[\"new\"]\n",
    "        if chosen_model == \"--Select\":\n",
    "            layer_ls = [\"--Select\"]\n",
    "        else:\n",
    "            model = create_model(chosen_model)\n",
    "            layers.options = get_conv_layers(model)\n",
    "        K.clear_session()\n",
    "        \n",
    "    \n",
    "def show_button(sender):\n",
    "    image = None\n",
    "    for _, file_info in uploader.value.items():\n",
    "        image = Image.open(io.BytesIO(file_info['content']))\n",
    "    assert image is not None, \"Please upload an image.\"   \n",
    "    img = np.array(image)\n",
    "    image.close()\n",
    "    uploaded_img = widgets.Image(value=array2bytes(img))\n",
    "    grid[4:10,10:] = uploaded_img\n",
    "    grid[14,10:] = widgets.HTML('')\n",
    "    \n",
    "def vis_button(sender):\n",
    "    clear_output()\n",
    "    display(grid)\n",
    "    model_name = models.value\n",
    "    assert model_name != \"--Select\", \"Please select a model to work on.\"\n",
    "    model = create_model(model_name)\n",
    "    K.clear_session()\n",
    "    layer_name = layers.value\n",
    "    assert methods.value != \"--Select\", \"Please select a method for visualization\"\n",
    "    if methods.value == \"Filter vis\":\n",
    "        filters = extract_filter(model=model,layer_name=layer_name)\n",
    "        print(\"Visualize filters {} of {}\".format(layer_name, model_name))\n",
    "        print(\"Filter shape: {}\".format(filters.shape))\n",
    "        print(\"Visualize 3 first channels of max 6 first filters:\")\n",
    "        vis_filter(filters)\n",
    "    else:\n",
    "        image = None\n",
    "        for _, file_info in uploader.value.items():\n",
    "            image = Image.open(io.BytesIO(file_info['content']))\n",
    "        assert image is not None, \"This method of visualization requires an input image. Please upload one.\"\n",
    "        img = np.array(image)\n",
    "        image.close()\n",
    "        target_size = (model.input.shape[1], model.input.shape[2])\n",
    "        preprocess_input = getattr(getattr(tf.keras.applications,model_dicts[model_name]),\"preprocess_input\")\n",
    "        img = cv2.resize(img,target_size)\n",
    "        processed_img = preprocess_input(img)\n",
    "        \n",
    "        if methods.value == \"Feature map vis\":\n",
    "            feature_extract = FeaturesExtraction(model,layer_name)\n",
    "            feature_maps = feature_extract.extract_features(np.expand_dims(processed_img,axis=0))\n",
    "            print(\"Feature map shape: {}. Visualize maximum 64 feature maps.\".format(feature_maps.shape))\n",
    "            vis_feature_map(feature_maps)\n",
    "        if methods.value == \"Guided Backprop\":\n",
    "            guidedBP = GuidedBackprop(model=model,layerName=layer_name)\n",
    "            gb_cam = guidedBP.guided_backprop(np.expand_dims(img,axis=0),target_size)\n",
    "            gb_im = deprocess_image(gb_cam)\n",
    "            gb_im = cv2.cvtColor(gb_im, cv2.COLOR_BGR2RGB)\n",
    "            print(\"Guided Backpropagation from layer {}\".format(layer_name))\n",
    "            plt.imshow(gb_im)\n",
    "            plt.axis(\"off\")\n",
    "#     K.clear_session()\n",
    "\n",
    "def explain_button(sender):\n",
    "    image = None\n",
    "    for _, file_info in uploader.value.items():\n",
    "        image = Image.open(io.BytesIO(file_info['content']))\n",
    "    \n",
    "    assert image is not None, \"An input image required, please upload one.\"\n",
    "    img = np.array(image)\n",
    "    image.close()\n",
    "    model_name = models.value\n",
    "    assert model_name != \"--Select\", \"Please select a model to work on.\"\n",
    "    model = create_model(model_name)\n",
    "    K.clear_session()\n",
    "    target_size = (model.input.shape[1], model.input.shape[2])\n",
    "    preprocess_input = getattr(getattr(tf.keras.applications,model_dicts[model_name]),\"preprocess_input\")\n",
    "    crop_im = cv2.resize(img,target_size)\n",
    "    processed_im = preprocess_input(crop_im)\n",
    "    probs = model.predict(np.expand_dims(processed_im,axis=0))\n",
    "    classIdx = (-probs).argsort()[0][:5]\n",
    "    preds = decode_predictions(probs)[:5]\n",
    "    pred_ls = [\"{}:{}_{:.2f}\".format(y,x[1],x[2]) for y,x in zip(classIdx,preds[0])]\n",
    "    \n",
    "    gradCAM = GradCAM(model=model)\n",
    "    cam3 = gradCAM.compute_heatmap(image=np.expand_dims(processed_im,axis=0),classIdx=classIdx[0],upsample_size=target_size)\n",
    "    heatmap = overlay_gradCAM(crop_im,cam3)\n",
    "    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
    "    guidedBP = GuidedBackprop(model=model)\n",
    "    gb_cam = guidedBP.guided_backprop(np.expand_dims(processed_im,axis=0),target_size)\n",
    "    guided_gradcam = deprocess_image(gb_cam*cam3)\n",
    "    \n",
    "    clear_output()\n",
    "    display(grid)\n",
    "    classes.options = [\"--Select\"] + pred_ls\n",
    "    print(\"Top 5 prediction: \", pred_ls)\n",
    "    # Explain\n",
    "    print(\"\\nExplanation for class: \", pred_ls[0])\n",
    "    print(\"To explain for different classes, choose in the 'Vis class' dropdown and be patient in 5s.\")\n",
    "    fig, ax = plt.subplots(1,2,figsize=(8,16))\n",
    "    ax[0].imshow(heatmap)\n",
    "    ax[0].axis(\"off\")\n",
    "    ax[0].set_title(\"GradCAM\")\n",
    "    ax[1].imshow(guided_gradcam)\n",
    "    ax[1].axis(\"off\")\n",
    "    ax[1].set_title(\"Guided-GradCAM\")\n",
    "    plt.show()\n",
    "#     K.clear_session()\n",
    "    \n",
    "def on_change_vis_class(change):\n",
    "    if change[\"type\"] == \"change\" and change[\"name\"] == \"value\":\n",
    "        classIdx = int(classes.value.split(\":\")[0])\n",
    "        image = None\n",
    "        for _, file_info in uploader.value.items():\n",
    "            image = Image.open(io.BytesIO(file_info['content']))\n",
    "        assert image is not None, \"An input image required. Please upload one.\"\n",
    "        img = np.array(image)\n",
    "        image.close()\n",
    "        model_name = models.value\n",
    "        assert model_name != \"--Select\", \"Please select a model to work on.\"\n",
    "        model = create_model(model_name)\n",
    "        K.clear_session()\n",
    "        target_size = (model.input.shape[1], model.input.shape[2])\n",
    "        preprocess_input = getattr(getattr(tf.keras.applications,model_dicts[model_name]),\"preprocess_input\")\n",
    "        crop_im = cv2.resize(img,target_size)\n",
    "        processed_im = preprocess_input(crop_im)\n",
    "        \n",
    "        gradCAM = GradCAM(model=model)\n",
    "        cam3 = gradCAM.compute_heatmap(image=np.expand_dims(processed_im,axis=0),classIdx=classIdx,upsample_size=target_size)\n",
    "        heatmap = overlay_gradCAM(crop_im,cam3)\n",
    "        heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
    "        guidedBP = GuidedBackprop(model=model)\n",
    "        gb_cam = guidedBP.guided_backprop(np.expand_dims(processed_im,axis=0),target_size)\n",
    "        guided_gradcam = deprocess_image(gb_cam*cam3)\n",
    "        \n",
    "        clear_output()\n",
    "        display(grid)\n",
    "        # Explain\n",
    "        print(\"\\nExplanation for class: \", classes.value)\n",
    "        print(\"To explain for different classes, choose in the 'Vis class' dropdown and be patient in 5s.\")\n",
    "        fig, ax = plt.subplots(1,2,figsize=(8,16))\n",
    "        ax[0].imshow(heatmap)\n",
    "        ax[0].axis(\"off\")\n",
    "        ax[0].set_title(\"GradCAM\")\n",
    "        ax[1].imshow(guided_gradcam)\n",
    "        ax[1].axis(\"off\")\n",
    "        ax[1].set_title(\"Guided-GradCAM\")\n",
    "        plt.show()\n",
    "#     K.clear_session()\n",
    "        \n",
    "def deepdream_button(sender):\n",
    "    image = None\n",
    "    for _, file_info in uploader.value.items():\n",
    "        image = Image.open(io.BytesIO(file_info['content']))\n",
    "    assert image is not None, \"An input image required. Please upload one.\"\n",
    "    im = np.array(image)\n",
    "    image.close()\n",
    "    model_name = models.value\n",
    "    assert model_name != \"--Select\", \"Please select a model to work on.\"\n",
    "    model = create_model(model_name)\n",
    "    K.clear_session()\n",
    "    preprocess_input = getattr(getattr(tf.keras.applications,model_dicts[model_name]),\"preprocess_input\")\n",
    "    original_img = preprocess_deep_dream(im, preprocess_input)\n",
    "    conv_layers = get_conv_layers(model)\n",
    "    \n",
    "    deepDream = DeepDream(model, conv_layers)\n",
    "    img = deepDream.generate_deep_dream(original_img)\n",
    "    deepdream_im = deprocess_deep_dream(img.numpy())\n",
    "    clear_output()\n",
    "    display(grid)\n",
    "    display(widgets.Image(value=array2bytes(cv2.cvtColor(deepdream_im, cv2.COLOR_BGR2RGB))))\n",
    "#     K.clear_session()\n",
    "\n",
    "show_but.on_click(show_button)\n",
    "models.observe(on_change_model)\n",
    "vis_but.on_click(vis_button)\n",
    "explain_but.on_click(explain_button)\n",
    "classes.observe(on_change_vis_class)\n",
    "deep_dream_but.on_click(deepdream_button)"
   ]
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "GradCAM",
   "language": "python",
   "name": "gradcam"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
